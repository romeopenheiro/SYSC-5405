---
title: 'BIOM/SYSC 5405: Pattern Classification and Experiment Design'
author:
- name: Romeo Penheiro
  affiliation: Department of Cognitive Science, Carleton University
date: "11/09/2021"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
subtitle: Assignment 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, message = FALSE, echo=T}
# Install xfun so that I can use xfun::pkg_load2
if (!requireNamespace('xfun')) install.packages('xfun')
xf <- loadNamespace('xfun')

cran_packages = c(
                  "dplyr", 
                  "ggplot2", 
                  "knitr", 
                  "readxl", 
                  "tibble",
                  "skimr",
                  "kableExtra",
                  "gridExtra",
                  "here",
                  "utils",
                  "tidyr",
                  "stats",
                  "ggpubr",
                  "MASS"
                  )
if (length(cran_packages) != 0) xf$pkg_load2(cran_packages)

import::from(magrittr, '%>%')
gg <- import::from(ggplot2, .all=TRUE, .into={new.env()})
dp <- import::from(dplyr, .all=TRUE, .into={new.env()})
```

load the files


```{r}
pci_raw <- readxl::read_xls(path = here::here("data", "assigData1.xls"), 
                            sheet = "PCI")
```

```{r}
psipred_raw <- readxl::read_xls(path = here::here("data", "assigData1.xls"), 
                            sheet = "PSIPRED")
```

```{r}
feature_raw_data <- utils::read.table(file = here::here("data", "assigData2.tsv"), sep = '\t', header = TRUE)
feature_raw_data
```

# Explore the data 
```{r}
tibble::glimpse(pci_raw)
```

```{r}
tibble::glimpse(psipred_raw)
```

# Question 1: Classifier scores

```{r}
q3_length_pci <- gg$ggplot(data = pci_raw, mapping = gg$aes(x = Length, y = Q3)) +
  gg$geom_jitter()
q3_length_pci

```

```{r}
q3_length_psipred <- gg$ggplot(data = psipred_raw, mapping = gg$aes(x = Length, y = Q3)) +
  gg$geom_jitter()
q3_length_psipred

```
Based on these plots, there does not seem to be a correlation between Q3 accuracy 
with protein length for both the methods.

Spearmen co-relation between the two variables

```{r}
cor.test(pci_raw$Length, pci_raw$Q3,
         method = "spearman",
         exact = FALSE)
```

```{r}
cor.test(psipred_raw$Length, psipred_raw$Q3,
         method = "spearman",
         exact = FALSE)
```
Why did I use Spearman's correlation?
https://ademos.people.uic.edu/Chapter22.html
http://www.statstutor.ac.uk/resources/uploaded/spearmans.pdf
https://www.quora.com/What-is-the-difference-between-dependence-and-correlation

mean, median, and standard deviation of the Matthewsâ€™ correlation coefficien


```{r echo=T}
# Using the `skimr` function
# Create a template function for descriptives
my_skim <- skimr::skim_with(base = skimr::sfl(n = length, 
                                              missing =skimr::n_missing),
                            numeric = skimr::sfl(mean, 
                                                 sd, 
                                                 iqr = IQR, # stats::IQR
                                                 min, 
                                                 p25 = ~ quantile(., 1/4), 
                                                 median, 
                                                 p75 = ~ quantile(., 3/4), 
                                                 max
                                                 ), append = FALSE
) #sfl stands for "skimr function list"

```


```{r}
my_skim(pci_raw$CC)

```

```{r}
my_skim(psipred_raw$CC_AVG)
```

# Question 2: Feature data
# (a) Estimation of the class-conditional distribution parameters of each feature and for each class
```{r}
my_skim(feature_raw_data)
```

# (b) Plotting the histograms for each feature

## Wrangling the data

```{r}

tidy_data <- feature_raw_data %>% 
  tidyr::pivot_longer(names_to = "feature", 
               values_to = "values", 
               cols = everything())
```

```{r}
weight_tidy_data <- tidy_data %>%
  dp$filter(feature == c("W_apl", "W_orng", "W_grp"))

diameter_tidy_data <- tidy_data %>%
  dp$filter(feature == c("D_apl", "D_orng", "D_grp"))
```


## Histograms for weight feature
```{r}

gg$ggplot(data = weight_tidy_data, mapping = gg$aes(fill = feature, color = feature)) +
    gg$geom_histogram(mapping = gg$aes(x = values), alpha = 0.5, position = "identity", binwidth = 0.5)  +
    gg$labs(x = "Weight",
                 y = "Frequency",
                 title = "A histogram of the feature weight (binwidth = 0.5)")
```

```{r}

gg$ggplot(data = weight_tidy_data, mapping = gg$aes(fill = feature, color = feature)) +
    gg$geom_histogram(mapping = gg$aes(x = values), alpha = 0.5, position = "identity", binwidth = 1)  +
    gg$labs(x = "Weight",
                 y = "Frequency",
                 title = "A histogram of the feature weight (binwidth = 1)")
```

## Histograms for diameter feature

```{r}

gg$ggplot(data = diameter_tidy_data, mapping = gg$aes(fill = feature, color = feature)) +
    gg$geom_histogram(mapping = gg$aes(x = values), alpha = 0.5, position = "identity", binwidth = 10)  +
    gg$labs(x = "Weight",
                 y = "Frequency",
                 title = "A histogram of the feature diameter (binwidth = 10)")
```

```{r}

gg$ggplot(data = diameter_tidy_data, mapping = gg$aes(fill = feature, color = feature)) +
    gg$geom_histogram(mapping = gg$aes(x = values), alpha = 0.5, position = "identity", binwidth = 50)  +
    gg$labs(x = "Weight",
                 y = "Frequency",
                 title = "A histogram of the feature diameter (binwidth = 50)")
```

I'd prefer the feature diameter because this feature seems to be allow non-overlapping frequency distribution curve for apples, grapes, and oranges. This means that a classifier will be better able to distiguish between the three fruits. The feature weight does not have as distinguishing classification for the fruits.  

# (c) Testing for normality

```{r}
a <- unlist(weight_tidy_data$values)
b <- as.vector(a, mode='numeric')
c <- round(b, digits = 0)
```


```{r}
ggpubr::ggqqplot(c)
```

For the data, I used a QQ plot to test for normality. QQ plot allows us to make a correlation between our sample and the normal distribution. Generally, if the data follows a Gaussian distribution, then all the data points in the QQ plot falls along the `y = x` reference line. We cannot assume normality in the dataset because only some of the data falls in the reference line whil most of the data points are far from the normal line.

# Question 3: Generating data & the normal distribution
# (a)
```{r}
N <- 1000 # samples
set.seed(123)

# bivariate normal distribution
mu <- c(1.2, 3.1) 
sigma <- matrix(c(1.2, 0.7, 0.7, 3.3), 2) # Covariance matrix

```

# (b)
```{r}
bvn <- MASS::mvrnorm(N, mu = mu, Sigma = sigma ) # from MASS 

plot(bvn, main="Scatter plot of the data", xlab="V1 ", ylab="V2", ylim=c(-5,10), xlim=c(-5,10))

```

# (c) 
```{r}
# Determinant of Sigma
det(sigma)
```

```{r}
# Trace of Sigma
sum(diag(sigma))
```

```{r}
#Test for Positive definite
isSymmetric(sigma)
```


Sigma is positive definite because the determinant is greater than zero.


# (d) Eigenvectors and values of Sigma

```{r}
e <- eigen(sigma)
#Eigen vectors
e$values
#Eigen values
e$vectors
```

```{r}
# Ellipse for line of equiprobability

```


# (e) Plotting the PDF and CDF

```{r}
x_axis <- seq(-12, 12, by = .1)

y_axis_p <- dnorm(x_axis, mean = 3.3, sd = 0.3)
y_axis_c <- pnorm(x_axis, mean = 3.3, sd = 0.3)

plot(x_axis,y_axis_p, xlab="x", ylab="y", main="Probability Distribution Function")
plot(x_axis,y_axis_c, xlab="x", ylab="y", main="Cumulative Distribution Function")
```

